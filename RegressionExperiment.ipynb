{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup code\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16.0, 8.0) # set default size of plots\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (404, 13)\n",
      "Train labels shape:  (404,)\n",
      "Validation data shape:  (102, 13)\n",
      "Validation labels shape:  (102,)\n"
     ]
    }
   ],
   "source": [
    "# Load the raw housing_scale data.\n",
    "filename = 'dataset/housing_scale'\n",
    "X, y = load_svmlight_file(filename)\n",
    "\n",
    "# Split the data into train, and val sets.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.91702508 -0.76945545 -0.22159092 -0.84158416 -0.308534    0.03766704\n",
      "   0.33956011 -0.50958712 -0.26345231 -0.17459005  0.24225822  0.79955463\n",
      "  -0.3902572 ]]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: subtract the mean of each housing feature\n",
    "# first: compute the housing feature mean based on the training data\n",
    "\n",
    "_mean = np.mean(X_train, axis=0)\n",
    "print(_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second: subtract the mean from train and X_val data\n",
    "X_train -= _mean\n",
    "X_val -= _mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 14) (102, 14)\n"
     ]
    }
   ],
   "source": [
    "# third: append the bias dimension of ones\n",
    "X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "\n",
    "print(X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels shape:  (404, 1)\n",
      "Validation labels shape:  (102, 1)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation labels shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regresser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regresser_loss_naive(w, X_train, y_train, reg) return loss, grad\n",
    "\n",
    "regresser_loss_vectorized(w, X_train, y_train, reg) return loss, grad\n",
    "\n",
    "prediction = \n",
    "loss = 0.5 * (_y - y)**2 + reg * sum(W**2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresser_loss_naive(W, X, y, reg):\n",
    "    '''\n",
    "    linear regression loss function, naive implementation (with loops).\n",
    "    \n",
    "    Inputs:\n",
    "    - W: A numpy array of shape (D, 1) containing weights.\n",
    "    - X: A numpy array of shape (N, D) containing a minibatch of data.\n",
    "    - y: A numpy array of shape (N, 1) containing training labels.\n",
    "    - reg: (float) regularization strength\n",
    "    \n",
    "    Returns a tuple of:\n",
    "    - loss as single float\n",
    "    - gradient with respect to weights W; an array of same shape as W\n",
    "    '''\n",
    "    num_train = X.shape[0]\n",
    "    \n",
    "    loss = 0.0\n",
    "    grad = np.zeros(W.shape) # initialize the gradient as zero\n",
    "    \n",
    "    # compute the loss and the gradient\n",
    "    for i in range(num_train):\n",
    "        _y = np.sum(X[i] * W)\n",
    "        loss += (y[i][0] - _y)**2\n",
    "        grad += - 2 * X[i].T * (y[i][0] - _y)\n",
    "    loss /= num_train\n",
    "    grad /= num_train\n",
    "    \n",
    "    # Add regularization to the loss and gradient.\n",
    "    loss += reg * 0.5 * np.sum(np.square(W))\n",
    "    grad += reg * W\n",
    "    \n",
    "    return loss, grad\n",
    "\n",
    "def regresser_loss_vectorized(W, X, y, reg):\n",
    "    '''\n",
    "    linear regression loss function, vectorized implementation.\n",
    "    \n",
    "    Inputs and outputs are the same as regresser_loss_naive.\n",
    "    '''\n",
    "    _y = X.dot(W) # (404, 1)\n",
    "    loss = np.mean(np.square(y - _y)) + reg * 0.5 * np.sum(np.square(W))\n",
    "    grad = - 2 * X.T.dot(y - _y) / X.shape[0] + reg * W\n",
    "    return loss, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Check\n",
    "\n",
    "Performing a gradient check is as simple as comparing the analytic gradient to the numerical gradient. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_numerical_gradient(f, x, analytic_grad, h=1e-5):\n",
    "    \"\"\"\n",
    "    Evaluate a numeric gradient for a function that accepts a numpy\n",
    "    array and returns a numpy array.\n",
    "    \"\"\"\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "        \n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h\n",
    "        pos = f(x)\n",
    "        x[ix] = oldval - h\n",
    "        neg = f(x)\n",
    "        x[ix] = oldval\n",
    "\n",
    "        grad_numerical = (pos - neg) / (2 * h)\n",
    "        grad_analytic = analytic_grad[ix]\n",
    "        rel_error = abs(grad_numerical - grad_analytic) / (abs(grad_numerical) + abs(grad_analytic))\n",
    "        print('numerical: %f analytic: %f, relative error: %e' % (grad_numerical, grad_analytic, rel_error))\n",
    "        \n",
    "        it.iternext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient check with regularization turned off\n",
      "numerical: 1.450196 analytic: 1.450196, relative error: 2.500940e-09\n",
      "numerical: -3.240397 analytic: -3.240397, relative error: 1.674595e-09\n",
      "numerical: 4.489404 analytic: 4.489404, relative error: 4.655180e-09\n",
      "numerical: -1.516704 analytic: -1.516704, relative error: 1.586829e-08\n",
      "numerical: 3.886106 analytic: 3.886106, relative error: 3.878214e-09\n",
      "numerical: -3.181649 analytic: -3.181649, relative error: 1.135836e-09\n",
      "numerical: 4.368756 analytic: 4.368756, relative error: 3.308320e-09\n",
      "numerical: -1.940520 analytic: -1.940520, relative error: 2.548463e-09\n",
      "numerical: 5.329158 analytic: 5.329158, relative error: 2.154025e-09\n",
      "numerical: 5.378774 analytic: 5.378774, relative error: 4.449455e-09\n",
      "numerical: 4.349617 analytic: 4.349617, relative error: 1.702340e-09\n",
      "numerical: -2.730431 analytic: -2.730431, relative error: 7.580849e-10\n",
      "numerical: 5.300355 analytic: 5.300355, relative error: 1.074430e-09\n",
      "numerical: -45.044554 analytic: -45.044554, relative error: 6.107941e-10\n",
      "\n",
      "gradient check with regularization turned on\n",
      "numerical: 1.450196 analytic: 1.450196, relative error: 2.500940e-09\n",
      "numerical: -3.240397 analytic: -3.240397, relative error: 1.674595e-09\n",
      "numerical: 4.489404 analytic: 4.489404, relative error: 4.655180e-09\n",
      "numerical: -1.516704 analytic: -1.516704, relative error: 1.586829e-08\n",
      "numerical: 3.886106 analytic: 3.886106, relative error: 3.878214e-09\n",
      "numerical: -3.181649 analytic: -3.181649, relative error: 1.135836e-09\n",
      "numerical: 4.368756 analytic: 4.368756, relative error: 3.308320e-09\n",
      "numerical: -1.940520 analytic: -1.940520, relative error: 2.548463e-09\n",
      "numerical: 5.329158 analytic: 5.329158, relative error: 2.154025e-09\n",
      "numerical: 5.378774 analytic: 5.378774, relative error: 4.449455e-09\n",
      "numerical: 4.349617 analytic: 4.349617, relative error: 1.702340e-09\n",
      "numerical: -2.730431 analytic: -2.730431, relative error: 7.580849e-10\n",
      "numerical: 5.300355 analytic: 5.300355, relative error: 1.074430e-09\n",
      "numerical: -45.044554 analytic: -45.044554, relative error: 6.107941e-10\n"
     ]
    }
   ],
   "source": [
    "W = np.zeros((X_train.shape[1], 1))\n",
    "\n",
    "# do the gradient check with regularization turned off\n",
    "print('gradient check with regularization turned off')\n",
    "loss, grad = regresser_loss_naive(W, X_train, y_train, 0.0)\n",
    "f = lambda w: regresser_loss_naive(w, X_train, y_train, 0.0)[0]\n",
    "grad_numerical = eval_numerical_gradient(f, W, grad)\n",
    "\n",
    "# do the gradient check once again with regularization turned on\n",
    "print('\\ngradient check with regularization turned on')\n",
    "loss, grad = regresser_loss_naive(W, X_train, y_train, 0.5)\n",
    "f = lambda w: regresser_loss_naive(w, X_train, y_train, 0.5)[0]\n",
    "grad_numerical = eval_numerical_gradient(f, W, grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Comparison\n",
    "\n",
    "compare the performance of the naive implementation and vetorized implementation of gradient computing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive implementation computed in 0.011980s\n",
      "Vectorized implementation computed in 0.000250s\n",
      "difference of loss: 0.000000\n",
      "difference of gradient: 0.000000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = regresser_loss_naive(W, X_train, y_train, 0.5)\n",
    "toc = time.time()\n",
    "print('Naive implementation computed in %fs' % (toc - tic))\n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = regresser_loss_vectorized(W, X_train, y_train, 0.5)\n",
    "toc = time.time()\n",
    "print('Vectorized implementation computed in %fs' % (toc - tic))\n",
    "\n",
    "\n",
    "print('difference of loss: %f' % (loss_naive - loss_vectorized))\n",
    "difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('difference of gradient: %f' % difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1200: train loss: 588.034356\tvaluation loss: 606.274156\n",
      "iteration 100 / 1200: train loss: 414.155465\tvaluation loss: 437.078733\n",
      "iteration 200 / 1200: train loss: 310.078673\tvaluation loss: 334.630586\n",
      "iteration 300 / 1200: train loss: 247.436201\tvaluation loss: 272.148823\n",
      "iteration 400 / 1200: train loss: 209.531183\tvaluation loss: 233.745890\n",
      "iteration 500 / 1200: train loss: 186.468383\tvaluation loss: 209.931917\n",
      "iteration 600 / 1200: train loss: 172.350288\tvaluation loss: 195.005927\n",
      "iteration 700 / 1200: train loss: 163.645497\tvaluation loss: 185.526136\n",
      "iteration 800 / 1200: train loss: 158.230977\tvaluation loss: 179.405345\n",
      "iteration 900 / 1200: train loss: 154.825866\tvaluation loss: 175.372308\n",
      "iteration 1000 / 1200: train loss: 152.654814\tvaluation loss: 172.649238\n",
      "iteration 1100 / 1200: train loss: 151.246875\tvaluation loss: 170.757855\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# reg: regularization strength.\n",
    "# lr: learning rate for optimization.\n",
    "# num_iters: number of steps to take when optimizing\n",
    "reg = 0.5\n",
    "lr = 0.001\n",
    "num_iters=1200\n",
    "\n",
    "\n",
    "W = np.zeros((X_train.shape[1], 1))\n",
    "loss_train_history = []\n",
    "loss_val_history = []\n",
    "for i in range(num_iters):\n",
    "    loss_train, grad = regresser_loss_vectorized(W, X_train, y_train, reg)\n",
    "    W -= lr * grad\n",
    "    \n",
    "    loss_val, _ = regresser_loss_vectorized(W, X_val, y_val, reg)\n",
    "    \n",
    "    loss_train_history.append(loss_train)\n",
    "    loss_val_history.append(loss_val)\n",
    "    if i % 100 == 0:\n",
    "        print('iteration %d / %d: train loss: %f\\tvaluation loss: %f' \n",
    "              % (i, num_iters, loss_train, loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAAHwCAYAAACSZPPAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe0bbfec88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Training / Valuation loss')\n",
    "plt.plot(loss_train_history,'blue',label='Train')\n",
    "plt.plot(loss_val_history,'red',label='Test')\n",
    "plt.xlabel('Iteration times')\n",
    "plt.ylabel('Loss value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation\n",
    "\n",
    "Use the validation set to tune hyperparameters (regularization strength and learning rate).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.058086e-06, reg 7.198266e-02, train loss: 584.516553, validation loss: 584.516553\n",
      "lr 1.266723e-06, reg 1.084326e+00, train loss: 583.829730, validation loss: 583.829730\n",
      "lr 1.347777e-06, reg 3.049481e-02, train loss: 583.557369, validation loss: 583.557369\n",
      "lr 1.444651e-06, reg 1.145427e-05, train loss: 583.236884, validation loss: 583.236884\n",
      "lr 1.734862e-06, reg 6.547011e+04, train loss: 588.000389, validation loss: 588.000389\n",
      "lr 1.927306e-06, reg 2.221025e+01, train loss: 581.843650, validation loss: 581.843650\n",
      "lr 2.077748e-06, reg 1.371752e-02, train loss: 581.148267, validation loss: 581.148267\n",
      "lr 2.226243e-06, reg 1.746404e-03, train loss: 580.659412, validation loss: 580.659412\n",
      "lr 2.284139e-06, reg 8.675861e-04, train loss: 580.468978, validation loss: 580.468978\n",
      "lr 2.390856e-06, reg 9.816469e-04, train loss: 580.118163, validation loss: 580.118163\n",
      "lr 2.433741e-06, reg 1.144676e-03, train loss: 579.977254, validation loss: 579.977254\n",
      "lr 2.604670e-06, reg 1.393760e+04, train loss: 587.874828, validation loss: 587.874828\n",
      "lr 2.810569e-06, reg 1.383126e+00, train loss: 578.767536, validation loss: 578.767536\n",
      "lr 2.873379e-06, reg 3.257295e+02, train loss: 582.913046, validation loss: 582.913046\n",
      "lr 2.985923e-06, reg 1.191471e+00, train loss: 578.192340, validation loss: 578.192340\n",
      "lr 3.400485e-06, reg 4.793816e-01, train loss: 576.824307, validation loss: 576.824307\n",
      "lr 3.402680e-06, reg 5.971931e-03, train loss: 576.803705, validation loss: 576.803705\n",
      "lr 3.654571e-06, reg 7.061333e-01, train loss: 576.004739, validation loss: 576.004739\n",
      "lr 3.877391e-06, reg 3.367740e-03, train loss: 575.255793, validation loss: 575.255793\n",
      "lr 4.352392e-06, reg 1.215507e-04, train loss: 573.711465, validation loss: 573.711465\n",
      "lr 4.539643e-06, reg 2.595859e-03, train loss: 573.104106, validation loss: 573.104106\n",
      "lr 5.060853e-06, reg 1.113470e-04, train loss: 571.416810, validation loss: 571.416810\n",
      "lr 5.134723e-06, reg 1.475757e-05, train loss: 571.178132, validation loss: 571.178132\n",
      "lr 5.408620e-06, reg 1.778946e+03, train loss: 586.786410, validation loss: 586.786410\n",
      "lr 5.515150e-06, reg 6.510432e-04, train loss: 569.950765, validation loss: 569.950765\n",
      "lr 5.588664e-06, reg 8.502707e-04, train loss: 569.713932, validation loss: 569.713932\n",
      "lr 5.756211e-06, reg 1.528528e+01, train loss: 570.351766, validation loss: 570.351766\n",
      "lr 5.840605e-06, reg 1.172866e+04, train loss: 587.844791, validation loss: 587.844791\n",
      "lr 5.992425e-06, reg 4.387207e-01, train loss: 568.453092, validation loss: 568.453092\n",
      "lr 6.069984e-06, reg 3.231033e+02, train loss: 581.568340, validation loss: 581.568340\n",
      "lr 6.817071e-06, reg 6.489280e-01, train loss: 565.844864, validation loss: 565.844864\n",
      "lr 7.097674e-06, reg 3.043391e-05, train loss: 564.876132, validation loss: 564.876132\n",
      "lr 7.332353e-06, reg 2.071301e+00, train loss: 564.393863, validation loss: 564.393863\n",
      "lr 7.540863e-06, reg 1.334942e+00, train loss: 563.645548, validation loss: 563.645548\n",
      "lr 8.615099e-06, reg 1.912698e-01, train loss: 560.091196, validation loss: 560.091196\n",
      "lr 8.780232e-06, reg 4.927583e-05, train loss: 559.535649, validation loss: 559.535649\n",
      "lr 9.525148e-06, reg 9.558934e+03, train loss: 587.801777, validation loss: 587.801777\n",
      "lr 1.092056e-05, reg 3.600825e-04, train loss: 552.823067, validation loss: 552.823067\n",
      "lr 1.205314e-05, reg 2.191169e-05, train loss: 549.307064, validation loss: 549.307064\n",
      "lr 1.348837e-05, reg 7.064177e+04, train loss: 588.002876, validation loss: 588.002876\n",
      "lr 1.786586e-05, reg 4.404180e+02, train loss: 583.020501, validation loss: 583.020501\n",
      "lr 2.135523e-05, reg 1.701153e-04, train loss: 521.353363, validation loss: 521.353363\n",
      "lr 2.501936e-05, reg 1.953646e+04, train loss: 587.920539, validation loss: 587.920539\n",
      "lr 2.566444e-05, reg 2.348518e+01, train loss: 534.946186, validation loss: 534.946186\n",
      "lr 2.832098e-05, reg 3.723542e-01, train loss: 502.099321, validation loss: 502.099321\n",
      "lr 3.011368e-05, reg 1.001789e+01, train loss: 513.452320, validation loss: 513.452320\n",
      "lr 3.148396e-05, reg 7.429859e+04, train loss: 574.277187, validation loss: 574.277187\n",
      "lr 3.670420e-05, reg 2.412102e+01, train loss: 525.181839, validation loss: 525.181839\n",
      "lr 3.955901e-05, reg 4.553210e+00, train loss: 484.528809, validation loss: 484.528809\n",
      "lr 4.005327e-05, reg 1.165932e-05, train loss: 469.840751, validation loss: 469.840751\n",
      "lr 4.039821e-05, reg 1.182588e+02, train loss: 569.727722, validation loss: 569.727722\n",
      "lr 4.651031e-05, reg 2.411824e+00, train loss: 463.160601, validation loss: 463.160601\n",
      "lr 4.662651e-05, reg 1.452131e+00, train loss: 459.126517, validation loss: 459.126517\n",
      "lr 4.790835e-05, reg 1.550782e+03, train loss: 586.603172, validation loss: 586.603172\n",
      "lr 5.570561e-05, reg 1.420746e+03, train loss: 586.472469, validation loss: 586.472469\n",
      "lr 5.708072e-05, reg 5.831281e-04, train loss: 427.869834, validation loss: 427.869834\n",
      "lr 5.842626e-05, reg 3.970442e-03, train loss: 424.759582, validation loss: 424.759582\n",
      "lr 6.037697e-05, reg 2.441951e+01, train loss: 514.453181, validation loss: 514.453181\n",
      "lr 6.680130e-05, reg 2.734080e-03, train loss: 405.838858, validation loss: 405.838858\n",
      "lr 8.379891e-05, reg 1.913990e+02, train loss: 576.602551, validation loss: 576.602551\n",
      "lr 8.846689e-05, reg 7.803572e+03, train loss: 587.749480, validation loss: 587.749480\n",
      "lr 9.577681e-05, reg 9.583488e+02, train loss: 585.721328, validation loss: 585.721328\n",
      "lr 1.091307e-04, reg 1.018467e+04, train loss: 587.816062, validation loss: 587.816062\n",
      "lr 1.120812e-04, reg 5.035018e-02, train loss: 319.752665, validation loss: 319.752665\n",
      "lr 1.129632e-04, reg 4.574590e-03, train loss: 317.482409, validation loss: 317.482409\n",
      "lr 1.136288e-04, reg 6.948220e-01, train loss: 328.477035, validation loss: 328.477035\n",
      "lr 1.166544e-04, reg 2.699664e-04, train loss: 311.359853, validation loss: 311.359853\n",
      "lr 1.334101e-04, reg 1.957992e-03, train loss: 285.606856, validation loss: 285.606856\n",
      "lr 1.351551e-04, reg 7.451442e+00, train loss: 407.037362, validation loss: 407.037362\n",
      "lr 1.362252e-04, reg 4.235266e-04, train loss: 281.492483, validation loss: 281.492483\n",
      "lr 1.388997e-04, reg 1.846290e+03, train loss: 586.831851, validation loss: 586.831851\n",
      "lr 1.405674e-04, reg 4.104463e+03, train loss: 587.492934, validation loss: 587.492934\n",
      "lr 1.464142e-04, reg 3.009590e-01, train loss: 274.815518, validation loss: 274.815518\n",
      "lr 1.540310e-04, reg 3.191669e+02, train loss: 581.134261, validation loss: 581.134261\n",
      "lr 1.561588e-04, reg 1.402709e+02, train loss: 572.527145, validation loss: 572.527145\n",
      "lr 1.927194e-04, reg 5.354435e-01, train loss: 231.021354, validation loss: 231.021354\n",
      "lr 1.947663e-04, reg 9.989941e+03, train loss: 587.811808, validation loss: 587.811808\n",
      "lr 2.039739e-04, reg 7.182423e+00, train loss: 385.749382, validation loss: 385.749382\n",
      "lr 2.073918e-04, reg 6.285258e+02, train loss: 584.513584, validation loss: 584.513584\n",
      "lr 2.138460e-04, reg 1.372645e-03, train loss: 192.586923, validation loss: 192.586923\n",
      "lr 2.203669e-04, reg 5.715877e-01, train loss: 209.032202, validation loss: 209.032202\n",
      "lr 2.332243e-04, reg 1.313464e+01, train loss: 452.449227, validation loss: 452.449227\n",
      "lr 2.911595e-04, reg 1.747502e+01, train loss: 480.383410, validation loss: 480.383410\n",
      "lr 2.969445e-04, reg 8.040432e-01, train loss: 173.200698, validation loss: 173.200698\n",
      "lr 3.174763e-04, reg 3.035935e+04, train loss: 1074.212762, validation loss: 1074.212762\n",
      "lr 3.425936e-04, reg 1.774464e-04, train loss: 111.785607, validation loss: 111.785607\n",
      "lr 3.544283e-04, reg 5.494969e+00, train loss: 338.026757, validation loss: 338.026757\n",
      "lr 3.874020e-04, reg 3.124914e+01, train loss: 523.404821, validation loss: 523.404821\n",
      "lr 3.908193e-04, reg 4.457162e-01, train loss: 119.385749, validation loss: 119.385749\n",
      "lr 3.919001e-04, reg 5.526437e+03, train loss: 629.382589, validation loss: 629.382589\n",
      "lr 4.013682e-04, reg 8.333802e+01, train loss: 562.319377, validation loss: 562.319377\n",
      "lr 4.095120e-04, reg 9.270738e+00, train loss: 410.074430, validation loss: 410.074430\n",
      "lr 4.120059e-04, reg 1.903359e+00, train loss: 196.652615, validation loss: 196.652615\n",
      "lr 4.452763e-04, reg 6.457448e-04, train loss: 79.385434, validation loss: 79.385434\n",
      "lr 4.542560e-04, reg 2.639317e-04, train loss: 77.333021, validation loss: 77.333021\n",
      "lr 4.961726e-04, reg 1.029648e+03, train loss: 585.881011, validation loss: 585.881011\n",
      "lr 5.059835e-04, reg 8.970465e+00, train loss: 405.607021, validation loss: 405.607021\n",
      "lr 6.846776e-04, reg 4.951843e+01, train loss: 545.811084, validation loss: 545.811084\n",
      "lr 7.544893e-04, reg 4.388550e+01, train loss: 540.756717, validation loss: 540.756717\n",
      "lr 9.388663e-04, reg 6.822907e+02, train loss: 584.789752, validation loss: 584.789752\n",
      "lowest validation loss achieved: 77.333021\n"
     ]
    }
   ],
   "source": [
    "# first run coarse search\n",
    "# If the cost is 3 times greater than origin cost,break out early to avoid explosions\n",
    "\n",
    "max_count = 100\n",
    "\n",
    "results = {}\n",
    "lowest_loss = float('inf')   # The lowest validation loss that we have seen so far.\n",
    "best_W = None # The weight matrix that achieved thelowest validation loss.\n",
    "best_setup = None # the best hyperparameter to get the best_W, (lr, reg, num_iters)\n",
    "\n",
    "for i in range(max_count):\n",
    "    W = np.zeros((X_train.shape[1], 1))\n",
    "    reg = 10**np.random.uniform(-5, 5)\n",
    "    lr = 10**np.random.uniform(-6, -3)\n",
    "    \n",
    "    loss_init, _ = regresser_loss_vectorized(W, X_train, y_train, reg)\n",
    "    for i in range(1500):\n",
    "        loss, grad = regresser_loss_vectorized(W, X_train, y_train, reg)\n",
    "        W -= lr * grad\n",
    "        if loss > 3 * loss_init:\n",
    "            break\n",
    "    loss_train, _ = regresser_loss_vectorized(W, X_train, y_train, 0)\n",
    "    loss_val, _ = regresser_loss_vectorized(W, X_train, y_train, 0)\n",
    "    \n",
    "    results[lr, reg] = loss_train, loss_val\n",
    "    if loss_val < lowest_loss:\n",
    "        lowest_loss = loss_val\n",
    "        best_W = W\n",
    "        best_setup = (lr, reg, num_iters)\n",
    "\n",
    "\n",
    "for lr, reg in sorted(results):\n",
    "    loss_train, loss_val = results[(lr, reg)]\n",
    "    print('lr %e, reg %e, train loss: %f, validation loss: %f' % (\n",
    "                lr, reg, loss_train, loss_val))\n",
    "    \n",
    "print('lowest validation loss achieved: %f' % lowest_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.176395e-04, reg 9.187090e-01, train loss: 278.007091, validation loss: 278.007091\n",
      "lr 1.186615e-04, reg 1.065018e-01, train loss: 254.872478, validation loss: 254.872478\n",
      "lr 1.187522e-04, reg 4.961282e-04, train loss: 251.777719, validation loss: 251.777719\n",
      "lr 1.244828e-04, reg 7.664185e-04, train loss: 242.408533, validation loss: 242.408533\n",
      "lr 1.252933e-04, reg 3.432399e-03, train loss: 241.196328, validation loss: 241.196328\n",
      "lr 1.292731e-04, reg 2.434728e-03, train loss: 234.948479, validation loss: 234.948479\n",
      "lr 1.352621e-04, reg 3.621692e-04, train loss: 225.892348, validation loss: 225.892348\n",
      "lr 1.369520e-04, reg 3.914079e-03, train loss: 223.549559, validation loss: 223.549559\n",
      "lr 1.376252e-04, reg 6.607145e-05, train loss: 222.452342, validation loss: 222.452342\n",
      "lr 1.437323e-04, reg 3.691697e-02, train loss: 215.158070, validation loss: 215.158070\n",
      "lr 1.558946e-04, reg 1.309827e-02, train loss: 198.511859, validation loss: 198.511859\n",
      "lr 1.559476e-04, reg 2.889622e-01, train loss: 208.707325, validation loss: 208.707325\n",
      "lr 1.561626e-04, reg 5.556834e-03, train loss: 197.896408, validation loss: 197.896408\n",
      "lr 1.573296e-04, reg 1.178213e-03, train loss: 196.292703, validation loss: 196.292703\n",
      "lr 1.617760e-04, reg 5.092277e-01, train loss: 210.354300, validation loss: 210.354300\n",
      "lr 1.697866e-04, reg 1.630378e-02, train loss: 182.360448, validation loss: 182.360448\n",
      "lr 1.765419e-04, reg 9.555457e-05, train loss: 174.395342, validation loss: 174.395342\n",
      "lr 1.765658e-04, reg 1.955132e-01, train loss: 182.554484, validation loss: 182.554484\n",
      "lr 1.780557e-04, reg 6.370248e-03, train loss: 173.077679, validation loss: 173.077679\n",
      "lr 1.815829e-04, reg 1.453468e-02, train loss: 169.817080, validation loss: 169.817080\n",
      "lr 1.832558e-04, reg 7.166863e-04, train loss: 167.541335, validation loss: 167.541335\n",
      "lr 1.863814e-04, reg 2.440690e-01, train loss: 175.108265, validation loss: 175.108265\n",
      "lr 2.064847e-04, reg 2.900494e-01, train loss: 160.041586, validation loss: 160.041586\n",
      "lr 2.119705e-04, reg 7.840148e-04, train loss: 141.929076, validation loss: 141.929076\n",
      "lr 2.150740e-04, reg 2.956464e-04, train loss: 139.469505, validation loss: 139.469505\n",
      "lr 2.190804e-04, reg 2.927417e-02, train loss: 137.838608, validation loss: 137.838608\n",
      "lr 2.386124e-04, reg 8.685310e-03, train loss: 123.242306, validation loss: 123.242306\n",
      "lr 2.431163e-04, reg 2.690059e-04, train loss: 119.956828, validation loss: 119.956828\n",
      "lr 2.573001e-04, reg 2.875202e-05, train loss: 111.591732, validation loss: 111.591732\n",
      "lr 2.630689e-04, reg 4.420637e-04, train loss: 108.472089, validation loss: 108.472089\n",
      "lr 2.879753e-04, reg 9.416391e-02, train loss: 101.595128, validation loss: 101.595128\n",
      "lr 3.055312e-04, reg 8.592232e-03, train loss: 89.649473, validation loss: 89.649473\n",
      "lr 3.153121e-04, reg 2.832322e-01, train loss: 101.745394, validation loss: 101.745394\n",
      "lr 3.187082e-04, reg 1.659345e-04, train loss: 84.369598, validation loss: 84.369598\n",
      "lr 3.372236e-04, reg 1.611285e-02, train loss: 79.259118, validation loss: 79.259118\n",
      "lr 3.471492e-04, reg 6.305723e-04, train loss: 75.510639, validation loss: 75.510639\n",
      "lr 3.494495e-04, reg 5.713706e-03, train loss: 75.153222, validation loss: 75.153222\n",
      "lr 3.558821e-04, reg 4.548533e-01, train loss: 99.997498, validation loss: 99.997498\n",
      "lr 3.650078e-04, reg 2.419856e-02, train loss: 72.128350, validation loss: 72.128350\n",
      "lr 3.657164e-04, reg 1.246501e-04, train loss: 70.626128, validation loss: 70.626128\n",
      "lr 3.696377e-04, reg 3.056244e-01, train loss: 87.446743, validation loss: 87.446743\n",
      "lr 3.849125e-04, reg 6.824435e-01, train loss: 107.904755, validation loss: 107.904755\n",
      "lr 4.096930e-04, reg 1.159595e-04, train loss: 61.462360, validation loss: 61.462360\n",
      "lr 4.140910e-04, reg 2.741002e-02, train loss: 62.149114, validation loss: 62.149114\n",
      "lr 4.274206e-04, reg 1.106239e-03, train loss: 58.571804, validation loss: 58.571804\n",
      "lr 4.474518e-04, reg 6.325611e-03, train loss: 55.928692, validation loss: 55.928692\n",
      "lr 4.491621e-04, reg 3.763823e-05, train loss: 55.380090, validation loss: 55.380090\n",
      "lr 4.509740e-04, reg 6.531976e-04, train loss: 55.170730, validation loss: 55.170730\n",
      "lr 4.527121e-04, reg 5.707873e-05, train loss: 54.912997, validation loss: 54.912997\n",
      "lr 4.635047e-04, reg 2.375302e-04, train loss: 53.567883, validation loss: 53.567883\n",
      "lr 4.750326e-04, reg 4.600330e-05, train loss: 52.219376, validation loss: 52.219376\n",
      "lr 5.069224e-04, reg 4.390870e-01, train loss: 74.403813, validation loss: 74.403813\n",
      "lr 5.466271e-04, reg 8.188393e-02, train loss: 49.663042, validation loss: 49.663042\n",
      "lr 5.837658e-04, reg 2.888630e-02, train loss: 44.750915, validation loss: 44.750915\n",
      "lr 6.188946e-04, reg 9.739575e-05, train loss: 41.782266, validation loss: 41.782266\n",
      "lr 6.222674e-04, reg 4.855447e-02, train loss: 43.574244, validation loss: 43.574244\n",
      "lr 6.487827e-04, reg 6.271147e-01, train loss: 77.898085, validation loss: 77.898085\n",
      "lr 6.509198e-04, reg 4.607445e-03, train loss: 40.608479, validation loss: 40.608479\n",
      "lr 6.674244e-04, reg 9.515991e-04, train loss: 39.871370, validation loss: 39.871370\n",
      "lr 6.741694e-04, reg 8.222701e-05, train loss: 39.608339, validation loss: 39.608339\n",
      "lr 6.980831e-04, reg 1.513790e-03, train loss: 38.888412, validation loss: 38.888412\n",
      "lr 6.986879e-04, reg 1.704063e-04, train loss: 38.826220, validation loss: 38.826220\n",
      "lr 6.989325e-04, reg 6.746902e-02, train loss: 41.296076, validation loss: 41.296076\n",
      "lr 7.051222e-04, reg 5.924800e-05, train loss: 38.631314, validation loss: 38.631314\n",
      "lr 7.343790e-04, reg 8.044572e-01, train loss: 88.484355, validation loss: 88.484355\n",
      "lr 7.518902e-04, reg 9.602151e-05, train loss: 37.395326, validation loss: 37.395326\n",
      "lr 7.663253e-04, reg 6.785321e-03, train loss: 37.256540, validation loss: 37.256540\n",
      "lr 7.783824e-04, reg 4.785462e-02, train loss: 38.315899, validation loss: 38.315899\n",
      "lr 7.941256e-04, reg 2.345239e-02, train loss: 37.151280, validation loss: 37.151280\n",
      "lr 8.014620e-04, reg 4.944957e-02, train loss: 37.850860, validation loss: 37.850860\n",
      "lr 8.068770e-04, reg 6.541044e-05, train loss: 36.210567, validation loss: 36.210567\n",
      "lr 8.105809e-04, reg 5.998885e-04, train loss: 36.153452, validation loss: 36.153452\n",
      "lr 9.060726e-04, reg 1.024887e-04, train loss: 34.558201, validation loss: 34.558201\n",
      "lr 9.396391e-04, reg 4.868977e-01, train loss: 60.308632, validation loss: 60.308632\n",
      "lr 9.585755e-04, reg 2.603332e-01, train loss: 44.885538, validation loss: 44.885538\n",
      "lr 9.592552e-04, reg 2.305074e-01, train loss: 43.177169, validation loss: 43.177169\n",
      "lr 9.767440e-04, reg 1.671332e-01, train loss: 39.635121, validation loss: 39.635121\n",
      "lr 9.887834e-04, reg 9.618082e-02, train loss: 36.386770, validation loss: 36.386770\n",
      "lr 9.917206e-04, reg 8.030798e-01, train loss: 84.670647, validation loss: 84.670647\n",
      "lr 1.023562e-03, reg 6.497429e-02, train loss: 34.836394, validation loss: 34.836394\n",
      "lr 1.026343e-03, reg 4.164771e-02, train loss: 34.081240, validation loss: 34.081240\n",
      "lr 1.033415e-03, reg 4.472536e-01, train loss: 56.334084, validation loss: 56.334084\n",
      "lr 1.076133e-03, reg 3.895932e-02, train loss: 33.455222, validation loss: 33.455222\n",
      "lr 1.081251e-03, reg 2.065431e-04, train loss: 32.470420, validation loss: 32.470420\n",
      "lr 1.094345e-03, reg 3.389800e-02, train loss: 33.128880, validation loss: 33.128880\n",
      "lr 1.135149e-03, reg 4.562993e-03, train loss: 32.038927, validation loss: 32.038927\n",
      "lr 1.195072e-03, reg 8.394914e-05, train loss: 31.420164, validation loss: 31.420164\n",
      "lr 1.209251e-03, reg 1.496761e-04, train loss: 31.302531, validation loss: 31.302531\n",
      "lr 1.209614e-03, reg 2.561802e-03, train loss: 31.346079, validation loss: 31.346079\n",
      "lr 1.279447e-03, reg 6.108537e-05, train loss: 30.743944, validation loss: 30.743944\n",
      "lr 1.302838e-03, reg 2.756763e-02, train loss: 31.172178, validation loss: 31.172178\n",
      "lr 1.329719e-03, reg 6.532712e-02, train loss: 32.072867, validation loss: 32.072867\n",
      "lr 1.350292e-03, reg 6.516866e-05, train loss: 30.229358, validation loss: 30.229358\n",
      "lr 1.353403e-03, reg 2.145744e-05, train loss: 30.206924, validation loss: 30.206924\n",
      "lr 1.379188e-03, reg 2.704159e-03, train loss: 30.081938, validation loss: 30.081938\n",
      "lr 1.387318e-03, reg 8.607470e-05, train loss: 29.977506, validation loss: 29.977506\n",
      "lr 1.387457e-03, reg 1.478341e-04, train loss: 29.977738, validation loss: 29.977738\n",
      "lr 1.457295e-03, reg 4.766221e-01, train loss: 56.204839, validation loss: 56.204839\n",
      "lr 1.459493e-03, reg 1.113258e-05, train loss: 29.513977, validation loss: 29.513977\n",
      "lr 1.494990e-03, reg 4.780554e-04, train loss: 29.308810, validation loss: 29.308810\n",
      "lr 1.495145e-03, reg 7.385112e-02, train loss: 31.327487, validation loss: 31.327487\n",
      "lr 1.501544e-03, reg 6.286912e-04, train loss: 29.273077, validation loss: 29.273077\n",
      "lr 1.550906e-03, reg 2.017399e-02, train loss: 29.414786, validation loss: 29.414786\n",
      "lr 1.570460e-03, reg 7.219900e-03, train loss: 29.016060, validation loss: 29.016060\n",
      "lr 1.586359e-03, reg 6.970652e-01, train loss: 73.942338, validation loss: 73.942338\n",
      "lr 1.590036e-03, reg 6.288384e-03, train loss: 28.891337, validation loss: 28.891337\n",
      "lr 1.613453e-03, reg 4.332219e-02, train loss: 29.707733, validation loss: 29.707733\n",
      "lr 1.631768e-03, reg 1.568513e-01, train loss: 34.250229, validation loss: 34.250229\n",
      "lr 1.722757e-03, reg 2.490633e-05, train loss: 28.103081, validation loss: 28.103081\n",
      "lr 1.732993e-03, reg 1.268216e-03, train loss: 28.080351, validation loss: 28.080351\n",
      "lr 1.739010e-03, reg 6.401579e-02, train loss: 29.792704, validation loss: 29.792704\n",
      "lr 1.835671e-03, reg 1.062243e-05, train loss: 27.604879, validation loss: 27.604879\n",
      "lr 1.992152e-03, reg 8.515426e-03, train loss: 27.184963, validation loss: 27.184963\n",
      "lr 1.999774e-03, reg 1.995212e-03, train loss: 27.013979, validation loss: 27.013979\n",
      "lr 2.040246e-03, reg 7.775713e-01, train loss: 80.503039, validation loss: 80.503039\n",
      "lr 2.144269e-03, reg 1.030774e-02, train loss: 26.723019, validation loss: 26.723019\n",
      "lr 2.212368e-03, reg 1.235426e-02, train loss: 26.569399, validation loss: 26.569399\n",
      "lr 2.233073e-03, reg 9.039790e-05, train loss: 26.227845, validation loss: 26.227845\n",
      "lr 2.234643e-03, reg 3.947713e-02, train loss: 27.274799, validation loss: 27.274799\n",
      "lr 2.260835e-03, reg 4.775453e-05, train loss: 26.148282, validation loss: 26.148282\n",
      "lr 2.266811e-03, reg 3.963507e-03, train loss: 26.217283, validation loss: 26.217283\n",
      "lr 2.281951e-03, reg 4.790313e-01, train loss: 55.211603, validation loss: 55.211603\n",
      "lr 2.290433e-03, reg 1.149856e-03, train loss: 26.090264, validation loss: 26.090264\n",
      "lr 2.315412e-03, reg 1.021779e-05, train loss: 25.998441, validation loss: 25.998441\n",
      "lr 2.332949e-03, reg 1.549147e-01, train loss: 32.151122, validation loss: 32.151122\n",
      "lr 2.383657e-03, reg 7.739083e-01, train loss: 80.109605, validation loss: 80.109605\n",
      "lr 2.406955e-03, reg 9.738800e-01, train loss: 97.324990, validation loss: 97.324990\n",
      "lr 2.437727e-03, reg 2.725622e-01, train loss: 39.362276, validation loss: 39.362276\n",
      "lr 2.499954e-03, reg 1.620180e-02, train loss: 25.934477, validation loss: 25.934477\n",
      "lr 2.541930e-03, reg 4.647571e-05, train loss: 25.451789, validation loss: 25.451789\n",
      "lr 2.565040e-03, reg 7.114364e-01, train loss: 74.697055, validation loss: 74.697055\n",
      "lr 2.625824e-03, reg 1.067861e-03, train loss: 25.297023, validation loss: 25.297023\n",
      "lr 2.711113e-03, reg 3.764835e-04, train loss: 25.114152, validation loss: 25.114152\n",
      "lr 2.990679e-03, reg 4.335644e-03, train loss: 24.729073, validation loss: 24.729073\n",
      "lr 3.009677e-03, reg 1.379654e-05, train loss: 24.603468, validation loss: 24.603468\n",
      "lr 3.036904e-03, reg 1.193784e-01, train loss: 29.187843, validation loss: 29.187843\n",
      "lr 3.064432e-03, reg 4.469970e-04, train loss: 24.533006, validation loss: 24.533006\n",
      "lr 3.103541e-03, reg 2.970901e-01, train loss: 40.591791, validation loss: 40.591791\n",
      "lr 3.166114e-03, reg 2.275211e-05, train loss: 24.384191, validation loss: 24.384191\n",
      "lr 3.207038e-03, reg 7.199349e-02, train loss: 26.716097, validation loss: 26.716097\n",
      "lr 3.297532e-03, reg 2.108408e-03, train loss: 24.264691, validation loss: 24.264691\n",
      "lr 3.334308e-03, reg 1.838259e-01, train loss: 32.657156, validation loss: 32.657156\n",
      "lr 3.354901e-03, reg 5.050275e-05, train loss: 24.152690, validation loss: 24.152690\n",
      "lr 3.387535e-03, reg 1.647012e-02, train loss: 24.516897, validation loss: 24.516897\n",
      "lr 3.390951e-03, reg 7.300159e-02, train loss: 26.557797, validation loss: 26.557797\n",
      "lr 3.405128e-03, reg 1.044389e-02, train loss: 24.338452, validation loss: 24.338452\n",
      "lr 3.563895e-03, reg 2.821436e-05, train loss: 23.930532, validation loss: 23.930532\n",
      "lr 3.931558e-03, reg 3.652240e-05, train loss: 23.612434, validation loss: 23.612434\n",
      "lr 4.029731e-03, reg 3.341963e-03, train loss: 23.609396, validation loss: 23.609396\n",
      "lr 4.056775e-03, reg 8.279574e-03, train loss: 23.702511, validation loss: 23.702511\n",
      "lr 4.591985e-03, reg 4.840940e-05, train loss: 23.203716, validation loss: 23.203716\n",
      "lr 4.857281e-03, reg 1.506090e-02, train loss: 23.416891, validation loss: 23.416891\n",
      "lr 5.051712e-03, reg 3.399073e-01, train loss: 43.490477, validation loss: 43.490477\n",
      "lr 5.891014e-03, reg 1.100089e-03, train loss: 22.755807, validation loss: 22.755807\n",
      "lr 5.942027e-03, reg 3.622163e-02, train loss: 23.695437, validation loss: 23.695437\n",
      "lr 5.980083e-03, reg 3.096096e-01, train loss: 41.101436, validation loss: 41.101436\n",
      "lr 6.037075e-03, reg 2.592497e-04, train loss: 22.705760, validation loss: 22.705760\n",
      "lr 6.075127e-03, reg 1.977141e-01, train loss: 32.850878, validation loss: 32.850878\n",
      "lr 6.106833e-03, reg 3.970199e-03, train loss: 22.753727, validation loss: 22.753727\n",
      "lr 6.118314e-03, reg 1.064986e-03, train loss: 22.699894, validation loss: 22.699894\n",
      "lr 6.283987e-03, reg 1.439929e-02, train loss: 22.939924, validation loss: 22.939924\n",
      "lr 6.624484e-03, reg 1.310298e-01, train loss: 28.409192, validation loss: 28.409192\n",
      "lr 6.652114e-03, reg 4.464968e-05, train loss: 22.573485, validation loss: 22.573485\n",
      "lr 7.073009e-03, reg 1.107200e-03, train loss: 22.517537, validation loss: 22.517537\n",
      "lr 7.424701e-03, reg 5.677921e-01, train loss: 62.267998, validation loss: 62.267998\n",
      "lr 7.550012e-03, reg 1.449248e-04, train loss: 22.433999, validation loss: 22.433999\n",
      "lr 7.623559e-03, reg 3.428462e-04, train loss: 22.427029, validation loss: 22.427029\n",
      "lr 7.768712e-03, reg 1.863353e-04, train loss: 22.406338, validation loss: 22.406338\n",
      "lr 7.949732e-03, reg 4.638497e-02, train loss: 23.740430, validation loss: 23.740430\n",
      "lr 8.206849e-03, reg 1.021882e-04, train loss: 22.354180, validation loss: 22.354180\n",
      "lr 8.341575e-03, reg 2.001894e-04, train loss: 22.341081, validation loss: 22.341081\n",
      "lr 8.391538e-03, reg 1.256776e-04, train loss: 22.334916, validation loss: 22.334916\n",
      "lr 8.453368e-03, reg 2.725274e-02, train loss: 22.968938, validation loss: 22.968938\n",
      "lr 8.686128e-03, reg 2.063648e-02, train loss: 22.741566, validation loss: 22.741566\n",
      "lr 8.917005e-03, reg 1.977432e-04, train loss: 22.285443, validation loss: 22.285443\n",
      "lr 9.547978e-03, reg 6.430241e-01, train loss: 68.715826, validation loss: 68.715826\n",
      "lr 9.776963e-03, reg 5.175225e-04, train loss: 22.220648, validation loss: 22.220648\n",
      "lr 9.974467e-03, reg 4.228093e-02, train loss: 23.406701, validation loss: 23.406701\n",
      "lr 1.005167e-02, reg 2.123068e-05, train loss: 22.195661, validation loss: 22.195661\n",
      "lr 1.009995e-02, reg 4.486141e-05, train loss: 22.192729, validation loss: 22.192729\n",
      "lr 1.027917e-02, reg 3.745114e-04, train loss: 22.185013, validation loss: 22.185013\n",
      "lr 1.057666e-02, reg 1.158428e-05, train loss: 22.162550, validation loss: 22.162550\n",
      "lr 1.057802e-02, reg 1.292072e-04, train loss: 22.163817, validation loss: 22.163817\n",
      "lr 1.092316e-02, reg 7.342862e-03, train loss: 22.253179, validation loss: 22.253179\n",
      "lr 1.133640e-02, reg 6.555929e-04, train loss: 22.128617, validation loss: 22.128617\n",
      "lr 1.162527e-02, reg 8.448273e-03, train loss: 22.237582, validation loss: 22.237582\n",
      "lr 1.183328e-02, reg 1.044970e-05, train loss: 22.097757, validation loss: 22.097757\n",
      "lr 1.187898e-02, reg 3.243199e-02, train loss: 22.928021, validation loss: 22.928021\n",
      "lr 1.207557e-02, reg 5.228446e-03, train loss: 22.158471, validation loss: 22.158471\n",
      "lr 1.207930e-02, reg 4.859044e-02, train loss: 23.591609, validation loss: 23.591609\n",
      "lr 1.240134e-02, reg 1.016116e-02, train loss: 22.238020, validation loss: 22.238020\n",
      "lr 1.327233e-02, reg 2.499092e-01, train loss: 36.540211, validation loss: 36.540211\n",
      "lr 1.332097e-02, reg 8.860777e-05, train loss: 22.041186, validation loss: 22.041186\n",
      "lr 1.372480e-02, reg 1.533290e-04, train loss: 22.029028, validation loss: 22.029028\n",
      "lr 1.509538e-02, reg 6.300839e-05, train loss: 21.991450, validation loss: 21.991450\n",
      "lr 1.536732e-02, reg 2.831785e-03, train loss: 22.016948, validation loss: 22.016948\n",
      "lr 1.634019e-02, reg 1.935504e-01, train loss: 32.456905, validation loss: 32.456905\n",
      "lr 1.684483e-02, reg 6.671193e-04, train loss: 21.962425, validation loss: 21.962425\n",
      "lr 1.713341e-02, reg 2.216853e-02, train loss: 22.439008, validation loss: 22.439008\n",
      "lr 1.830271e-02, reg 2.644429e-02, train loss: 22.569472, validation loss: 22.569472\n",
      "lr 1.862299e-02, reg 5.161805e-01, train loss: 57.891886, validation loss: 57.891886\n",
      "lr 1.866941e-02, reg 2.175717e-05, train loss: 21.930342, validation loss: 21.930342\n",
      "lr 1.887475e-02, reg 6.631729e-01, train loss: 70.452620, validation loss: 70.452620\n",
      "lr 1.970868e-02, reg 5.083405e-04, train loss: 21.923060, validation loss: 21.923060\n",
      "lr 2.014382e-02, reg 6.035044e-02, train loss: 24.070135, validation loss: 24.070135\n",
      "lr 2.018132e-02, reg 2.460744e-03, train loss: 21.938247, validation loss: 21.938247\n",
      "lr 2.210331e-02, reg 4.202497e-03, train loss: 21.943860, validation loss: 21.943860\n",
      "lr 2.298250e-02, reg 8.328818e-05, train loss: 21.894895, validation loss: 21.894895\n",
      "lr 2.301263e-02, reg 1.256480e-05, train loss: 21.894251, validation loss: 21.894251\n",
      "lr 2.371612e-02, reg 1.472861e-04, train loss: 21.891509, validation loss: 21.891509\n",
      "lr 2.571961e-02, reg 1.205197e-04, train loss: 21.883091, validation loss: 21.883091\n",
      "lr 2.881985e-02, reg 4.561088e-03, train loss: 21.916504, validation loss: 21.916504\n",
      "lr 3.099411e-02, reg 2.643345e-02, train loss: 22.507528, validation loss: 22.507528\n",
      "lr 3.167090e-02, reg 4.483030e-02, train loss: 23.289219, validation loss: 23.289219\n",
      "lr 3.177658e-02, reg 2.997672e-04, train loss: 21.870952, validation loss: 21.870952\n",
      "lr 3.185781e-02, reg 1.174631e-05, train loss: 21.869650, validation loss: 21.869650\n",
      "lr 3.279526e-02, reg 1.640723e-02, train loss: 22.167693, validation loss: 22.167693\n",
      "lr 3.283361e-02, reg 6.305038e-02, train loss: 24.198076, validation loss: 24.198076\n",
      "lr 3.496478e-02, reg 3.184235e-01, train loss: 41.762083, validation loss: 41.762083\n",
      "lr 3.510270e-02, reg 3.196525e-03, train loss: 21.888245, validation loss: 21.888245\n",
      "lr 3.658900e-02, reg 2.711262e-01, train loss: 38.130007, validation loss: 38.130007\n",
      "lr 3.672275e-02, reg 2.499234e-05, train loss: 21.865829, validation loss: 21.865829\n",
      "lr 3.750389e-02, reg 1.258298e-02, train loss: 22.056968, validation loss: 22.056968\n",
      "lr 3.792353e-02, reg 5.336419e-05, train loss: 21.865347, validation loss: 21.865347\n",
      "lr 3.884966e-02, reg 1.754966e-03, train loss: 21.872773, validation loss: 21.872773\n",
      "lr 3.914305e-02, reg 2.666849e-01, train loss: 37.795014, validation loss: 37.795014\n",
      "lr 4.027858e-02, reg 1.602924e-02, train loss: 22.148259, validation loss: 22.148259\n",
      "lr 4.031964e-02, reg 8.111855e-03, train loss: 21.955259, validation loss: 21.955259\n",
      "lr 4.065240e-02, reg 7.943439e-04, train loss: 21.866734, validation loss: 21.866734\n",
      "lr 4.309926e-02, reg 4.956378e-01, train loss: 56.164304, validation loss: 56.164304\n",
      "lr 4.566155e-02, reg 1.051480e-02, train loss: 22.001912, validation loss: 22.001912\n",
      "lr 4.669189e-02, reg 4.536732e-02, train loss: 23.311491, validation loss: 23.311491\n",
      "lr 4.744022e-02, reg 1.879607e-03, train loss: 21.870334, validation loss: 21.870334\n",
      "lr 4.961885e-02, reg 1.398960e-03, train loss: 21.867267, validation loss: 21.867267\n",
      "lr 5.085673e-02, reg 1.017772e-03, train loss: 21.865459, validation loss: 21.865459\n",
      "lr 5.121646e-02, reg 3.887744e-02, train loss: 23.013359, validation loss: 23.013359\n",
      "lr 5.289201e-02, reg 2.699574e-02, train loss: 22.518620, validation loss: 22.518620\n",
      "lr 5.456010e-02, reg 3.865006e-04, train loss: 21.863417, validation loss: 21.863417\n",
      "lr 5.880817e-02, reg 1.180739e-03, train loss: 21.865482, validation loss: 21.865482\n",
      "lr 6.052238e-02, reg 3.554204e-04, train loss: 21.863185, validation loss: 21.863185\n",
      "lr 6.348046e-02, reg 3.469512e-05, train loss: 21.862841, validation loss: 21.862841\n",
      "lr 6.660443e-02, reg 1.813512e-04, train loss: 21.862910, validation loss: 21.862910\n",
      "lr 6.663136e-02, reg 3.647494e-05, train loss: 21.862826, validation loss: 21.862826\n",
      "lr 6.997676e-02, reg 1.978891e-05, train loss: 21.862811, validation loss: 21.862811\n",
      "lr 7.110740e-02, reg 1.194785e-03, train loss: 21.865179, validation loss: 21.865179\n",
      "lr 7.289752e-02, reg 3.206393e-02, train loss: 22.720200, validation loss: 22.720200\n",
      "lr 7.323593e-02, reg 6.298586e-01, train loss: 67.582866, validation loss: 67.582866\n",
      "lr 7.777412e-02, reg 3.330209e-04, train loss: 21.863005, validation loss: 21.863005\n",
      "lr 7.884129e-02, reg 2.621105e-03, train loss: 21.873167, validation loss: 21.873167\n",
      "lr 8.158547e-02, reg 1.537784e-05, train loss: 21.862799, validation loss: 21.862799\n",
      "lr 8.263414e-02, reg 2.566144e-03, train loss: 21.872717, validation loss: 21.872717\n",
      "lr 8.309492e-02, reg 3.865851e-04, train loss: 21.863057, validation loss: 21.863057\n",
      "lr 8.773699e-02, reg 5.276263e-04, train loss: 21.863257, validation loss: 21.863257\n",
      "lr 9.030610e-02, reg 5.345526e-01, train loss: 59.444160, validation loss: 59.444160\n",
      "lr 9.179391e-02, reg 4.242261e-05, train loss: 21.862801, validation loss: 21.862801\n",
      "lr 9.662341e-02, reg 5.439466e-04, train loss: 21.863274, validation loss: 21.863274\n",
      "lowest validation loss achieved: 21.862799\n"
     ]
    }
   ],
   "source": [
    "# observe that low cost achieved when lr (1e-4, 1e-2), reg (1e-5, 1e-3) \n",
    "# then run fine search\n",
    "\n",
    "max_count = 256\n",
    "\n",
    "results = {}\n",
    "lowest_loss = float('inf')   # The lowest validation loss that we have seen so far.\n",
    "best_W = None # The weight matrix that achieved thelowest validation loss.\n",
    "best_setup = None # the best hyperparameter to get the best_W, (lr, reg, num_iters)\n",
    "\n",
    "for i in range(max_count):\n",
    "    W = np.zeros((X_train.shape[1], 1))\n",
    "    reg = 10**np.random.uniform(-5, 0)\n",
    "    lr = 10**np.random.uniform(-4, -1)\n",
    "    \n",
    "    loss_init, _ = regresser_loss_vectorized(W, X_train, y_train, reg)\n",
    "    for i in range(2000):\n",
    "        loss, grad = regresser_loss_vectorized(W, X_train, y_train, reg)\n",
    "        W -= lr * grad\n",
    "        if loss > 3 * loss_init:\n",
    "            break\n",
    "    loss_train, _ = regresser_loss_vectorized(W, X_train, y_train, 0)\n",
    "    loss_val, _ = regresser_loss_vectorized(W, X_train, y_train, 0)\n",
    "    \n",
    "    results[lr, reg] = loss_train, loss_val\n",
    "    if loss_val < lowest_loss:\n",
    "        lowest_loss = loss_val\n",
    "        best_W = W\n",
    "        best_setup = (lr, reg, num_iters)\n",
    "\n",
    "\n",
    "for lr, reg in sorted(results):\n",
    "    loss_train, loss_val = results[(lr, reg)]\n",
    "    print('lr %e, reg %e, train loss: %f, validation loss: %f' % (\n",
    "                lr, reg, loss_train, loss_val))\n",
    "    \n",
    "print('lowest validation loss achieved: %f' % lowest_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.081585, regularization strength: 0.000015\n",
      "training loss: 21.8692545306\n",
      "valuation loss: 23.3866301319\n"
     ]
    }
   ],
   "source": [
    "print('learning rate: %f, regularization strength: %f' \n",
    "      % (best_setup[0], best_setup[1]))\n",
    "loss_train, _ = regresser_loss_vectorized(best_W, X_train, y_train, best_setup[1])\n",
    "loss_val, _ = regresser_loss_vectorized(best_W, X_val, y_val, best_setup[1])\n",
    "print('training loss:', loss_train)\n",
    "print('valuation loss:', loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 100: train loss: 588.034356\tvaluation loss: 446.435230\n"
     ]
    }
   ],
   "source": [
    "reg = best_setup[1]\n",
    "lr = best_setup[0]\n",
    "num_iters=100\n",
    "\n",
    "W = np.zeros((X_train.shape[1], 1))\n",
    "loss_train_history = []\n",
    "loss_val_history = []\n",
    "for i in range(num_iters):\n",
    "    loss_train, grad = regresser_loss_vectorized(W, X_train, y_train, reg)\n",
    "    W -= lr * grad\n",
    "    \n",
    "    loss_val, _ = regresser_loss_vectorized(W, X_val, y_val, reg)\n",
    "    \n",
    "    loss_train_history.append(loss_train)\n",
    "    loss_val_history.append(loss_val)\n",
    "    if i % 100 == 0:\n",
    "        print('iteration %d / %d: train loss: %f\\tvaluation loss: %f' \n",
    "              % (i, num_iters, loss_train, loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAAHwCAYAAACSZPPAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSPs/mjlscrRC3l0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efe09b8d1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Training / Valuation loss')\n",
    "plt.plot(loss_train_history,'blue',label='Train')\n",
    "plt.plot(loss_val_history,'red',label='Test')\n",
    "plt.xlabel('Iteration times')\n",
    "plt.ylabel('Loss value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
